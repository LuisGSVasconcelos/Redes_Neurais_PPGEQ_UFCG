# -*- coding: utf-8 -*-
"""RN_CAP_12_TCLab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15mQXE6BNg8O8F5LGk9abDaH7ZrvfF6Eh
"""

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

# Instalar pacotes necessários no Google Colab
!pip install pyreadr

# Importações gerais
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Pré-processamento
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

# Redes neurais com Keras (TensorFlow)
from tensorflow.keras import Sequential, regularizers
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical


# Leitura do arquivo com dados de treinamento
dados = pd.read_csv('TCLab_train_data.txt')

# Extração de variáveis
potencia_aquecedor = dados[['Q1']].values
temperatura = dados[['T1']].values

# Plot da temperatura
plt.plot(temperatura, 'k')
plt.ylabel('Temperatura')
plt.xlabel('Tempo (s)')
plt.title("Temperatura ao longo do tempo")
plt.show()

# Plot da potência
plt.plot(potencia_aquecedor)
plt.ylabel('Potência do Aquecedor')
plt.xlabel('Tempo (s)')
plt.title("Potência aplicada ao longo do tempo")
plt.show()

# Entradas e saída
X = dados[['T1', 'Q1']].values
y = dados[['T1']].values

# Normalização
X_scaler = StandardScaler()
X_scaled = X_scaler.fit_transform(X)

y_scaler = StandardScaler()
y_scaled = y_scaler.fit_transform(y)

# Sequencialização dos dados para LSTM
n_passos = 70
X_seq, y_seq = [], []

for i in range(n_passos, X_scaled.shape[0]):
    X_seq.append(X_scaled[i-n_passos:i])
    y_seq.append(y_scaled[i])

X_seq = np.array(X_seq)
y_seq = np.array(y_seq)

# Definição do modelo
modelo = Sequential()
modelo.add(LSTM(units=25, kernel_regularizer=regularizers.L1(0.001), input_shape=(n_passos, 2)))
modelo.add(Dense(units=1))

# Compilação e treinamento
modelo.compile(optimizer='adam', loss='mse')
parada_antecipada = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

historico = modelo.fit(X_seq, y_seq, epochs=100, batch_size=250, validation_split=0.3, callbacks=[parada_antecipada])

# Leitura do conjunto de teste
dados_teste = pd.read_csv('TCLab_test_data.txt')
X_teste = dados_teste[['T1', 'Q1']].values
y_teste = dados_teste[['T1']].values

# Normalização
X_teste_scaled = X_scaler.transform(X_teste)
y_teste_scaled = y_scaler.transform(y_teste)

# Sequencialização
X_teste_seq, y_teste_seq = [], []
for i in range(n_passos, X_teste_scaled.shape[0]):
    X_teste_seq.append(X_teste_scaled[i-n_passos:i])
    y_teste_seq.append(y_teste_scaled[i])

X_teste_seq = np.array(X_teste_seq)
y_teste_seq = np.array(y_teste_seq)

# Previsão e inversão da escala
y_pred_scaled = modelo.predict(X_teste_seq)
y_pred = y_scaler.inverse_transform(y_pred_scaled)


# LSTM com Dados do TCLab
# Leitura dos dados
dados = pd.read_csv('TCLab_train_data.txt')
X = dados[['T1', 'Q1']].values
y = dados[['T1']].values

# Normalização
X_scaler = StandardScaler()
X_scaled = X_scaler.fit_transform(X)
y_scaler = StandardScaler()
y_scaled = y_scaler.fit_transform(y)

# Preparação em sequência
n_passos = 70
X_seq, y_seq = [], []
for i in range(n_passos, X_scaled.shape[0]):
    X_seq.append(X_scaled[i-n_passos:i])
    y_seq.append(y_scaled[i])
X_seq, y_seq = np.array(X_seq), np.array(y_seq)

# Modelo LSTM
modelo = Sequential()
modelo.add(LSTM(units=25, kernel_regularizer=regularizers.L1(0.001), input_shape=(n_passos, 2)))
modelo.add(Dense(1))
modelo.compile(optimizer='adam', loss='mse')
es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
modelo.fit(X_seq, y_seq, epochs=100, batch_size=250, validation_split=0.3, callbacks=[es])

# Avaliação no teste
dados_teste = pd.read_csv('TCLab_test_data.txt')
X_teste = dados_teste[['T1', 'Q1']].values
y_teste = dados_teste[['T1']].values
X_teste_scaled = X_scaler.transform(X_teste)
y_teste_scaled = y_scaler.transform(y_teste)
X_teste_seq, y_teste_seq = [], []
for i in range(n_passos, X_teste_scaled.shape[0]):
    X_teste_seq.append(X_teste_scaled[i-n_passos:i])
    y_teste_seq.append(y_teste_scaled[i])
X_teste_seq, y_teste_seq = np.array(X_teste_seq), np.array(y_teste_seq)
y_pred_scaled = modelo.predict(X_teste_seq)
y_pred = y_scaler.inverse_transform(y_pred_scaled)

# LSTM com Dados do TEP - Classificação de Falhas


# Leitura dos arquivos RData
import pyreadr
fault_free_train = pyreadr.read_r('TEP_FaultFree_Training.RData')['fault_free_training']
fault_free_test = pyreadr.read_r('TEP_FaultFree_Testing.RData')['fault_free_testing']
faulty_train = pyreadr.read_r('TEP_Faulty_Training.RData')['faulty_training']
faulty_test = pyreadr.read_r('TEP_Faulty_Testing.RData')['faulty_testing']

# Remoção das falhas 3, 9 e 15
for fault in [3, 9, 15]:
    faulty_train = faulty_train[faulty_train['faultNumber'] != fault]
    faulty_test = faulty_test[faulty_test['faultNumber'] != fault]

# Separação de validação e ajuste do desequilíbrio
val_free = fault_free_train[fault_free_train['simulationRun'] > 400]
fault_free_train = fault_free_train[fault_free_train['simulationRun'] <= 400]

val_fault = faulty_train[faulty_train['simulationRun'] > 490]
faulty_train = faulty_train[faulty_train['simulationRun'] <= 50]

# Conversão para numpy
fault_free_train = fault_free_train.values
val_free = val_free.values
fault_free_test = fault_free_test.values
faulty_train = faulty_train.values
val_fault = val_fault.values
faulty_test = faulty_test.values

# Concatenação
train_data = np.vstack((fault_free_train, faulty_train))
val_data = np.vstack((val_free, val_fault))
test_data = np.vstack((fault_free_test, faulty_test))

# Separação de X e y
X_train, y_train = train_data[:, 3:], train_data[:, 0]
X_val, y_val = val_data[:, 3:], val_data[:, 0]
X_test, y_test = test_data[:, 3:], test_data[:, 0]

# Normalização
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Sequencialização
n_passos_train, n_passos_test = 500, 960
def criar_sequencias(X, y, tamanho):
    X_seq, y_seq = [], []
    for i in range(0, X.shape[0], tamanho):
        X_seq.append(X[i:i+tamanho])
        y_seq.append(y[i])
    return np.array(X_seq), np.array(y_seq)

X_train_seq, y_train_seq = criar_sequencias(X_train_scaled, y_train, n_passos_train)
X_val_seq, y_val_seq = criar_sequencias(X_val_scaled, y_val, n_passos_train)
X_test_seq, y_test_seq = criar_sequencias(X_test_scaled, y_test, n_passos_test)

# One-hot encoding
Y_train_seq = to_categorical(y_train_seq, num_classes=21)
Y_val_seq = to_categorical(y_val_seq, num_classes=21)
Y_test_seq = to_categorical(y_test_seq, num_classes=21)

# Modelo LSTM para classificação
modelo = Sequential()
modelo.add(LSTM(128, kernel_regularizer=regularizers.L1(0.0001), return_sequences=True, input_shape=(n_passos_train, 52)))
modelo.add(LSTM(64, kernel_regularizer=regularizers.L1(0.0001)))
modelo.add(Dense(21, activation='softmax'))

# Compilação e treinamento
modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
historico = modelo.fit(X_train_seq, Y_train_seq, epochs=100, batch_size=250,
                       validation_data=(X_val_seq, Y_val_seq), callbacks=[es])

# Avaliação
avaliacao = modelo.evaluate(X_test_seq, Y_test_seq)
print("Acurácia no teste:", avaliacao[1])

# Matriz de confusão
Y_pred = modelo.predict(X_test_seq)
y_pred = np.argmax(Y_pred, axis=1)
cm = confusion_matrix(y_test_seq, y_pred, labels=list(range(21)))

# Plot da matriz de confusão
sns.set(font_scale=1.2)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues')
plt.ylabel('Classe Real')
plt.xlabel('Classe Predita')
plt.title('Matriz de Confusão - TEP')
plt.show()

# Prognóstico de Falhas - RUL com dados PM e LSTM





# Leitura dos dados PM
train_df = pd.read_csv('PM_train.txt', sep=" ", header=None)
train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)  # colunas em branco
train_df.columns = ['EngineID', 'cycle', 'OPsetting1', 'OPsetting2', 'OPsetting3',
                    's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9',
                    's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17',
                    's18', 's19', 's20', 's21']

test_df = pd.read_csv('PM_test.txt', sep=" ", header=None)
test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)
test_df.columns = train_df.columns

truth_df = pd.read_csv('PM_truth.txt', sep=" ", header=None)
truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)
truth_df.columns = ['finalRUL']
truth_df['EngineID'] = truth_df.index + 1

# Criar RUL (Remaining Useful Life) e label binária para treino
max_cycle_train = train_df.groupby('EngineID')['cycle'].max().reset_index()
max_cycle_train.columns = ['EngineID', 'maxEngineCycle']
train_df = train_df.merge(max_cycle_train, on='EngineID')
train_df['engineRUL'] = train_df['maxEngineCycle'] - train_df['cycle']
train_df.drop('maxEngineCycle', axis=1, inplace=True)
w1 = 30
train_df['binaryLabel'] = (train_df['engineRUL'] <= w1).astype(int)

# Para dados de teste
max_cycle_test = test_df.groupby('EngineID')['cycle'].max().reset_index()
max_cycle_test.columns = ['EngineID', 'maxEngineCycle']
truth_df = truth_df.merge(max_cycle_test, on='EngineID')
truth_df['maxEngineCycle'] += truth_df['finalRUL']
truth_df.drop('finalRUL', axis=1, inplace=True)

test_df = test_df.merge(truth_df, on='EngineID')
test_df['engineRUL'] = test_df['maxEngineCycle'] - test_df['cycle']
test_df.drop('maxEngineCycle', axis=1, inplace=True)
test_df['binaryLabel'] = (test_df['engineRUL'] <= w1).astype(int)

# Escalar variáveis (exceto colunas que não devem ser escaladas)
cols_para_escalar = train_df.columns.difference(['EngineID', 'cycle', 'engineRUL', 'binaryLabel'])

scaler = StandardScaler()
train_scaled = train_df.copy()
train_scaled[cols_para_escalar] = scaler.fit_transform(train_df[cols_para_escalar])

test_scaled = test_df.copy()
test_scaled[cols_para_escalar] = scaler.transform(test_df[cols_para_escalar])

# Função para gerar sequências para LSTM
def gerar_sequencias(df, n_steps):
    X_seq = []
    y_seq = []
    for engine_id in df['EngineID'].unique():
        engine_data = df[df['EngineID'] == engine_id]
        if engine_data.shape[0] >= n_steps:
            data_array = engine_data[cols_para_escalar.tolist() + ['binaryLabel']].values
            for i in range(n_steps, data_array.shape[0]):
                X_seq.append(data_array[i-n_steps:i, :-1])
                y_seq.append(data_array[i-1, -1])
    return np.array(X_seq), np.array(y_seq)

n_steps = 50
X_train_seq, y_train_seq = gerar_sequencias(train_scaled, n_steps)
X_test_seq, y_test_seq = gerar_sequencias(test_scaled, n_steps)

# Dividir treino e validação
X_train, X_val, y_train, y_val = train_test_split(X_train_seq, y_train_seq, stratify=y_train_seq, test_size=0.3, random_state=100)

# Modelo LSTM para classificação binária
modelo = Sequential()
modelo.add(LSTM(100, return_sequences=True, input_shape=(n_steps, len(cols_para_escalar))))
modelo.add(Dropout(0.2))
modelo.add(LSTM(50))
modelo.add(Dropout(0.2))
modelo.add(Dense(1, activation='sigmoid'))

modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

historico = modelo.fit(X_train, y_train, epochs=100, batch_size=250, validation_data=(X_val, y_val), callbacks=[es])

# Avaliação no teste
avaliacao = modelo.evaluate(X_test_seq, y_test_seq)
print(f"Acurácia no teste: {avaliacao[1]:.4f}")

# Matriz de confusão
y_pred_prob = modelo.predict(X_test_seq)
y_pred = (y_pred_prob > 0.5).astype(int)

cm = confusion_matrix(y_test_seq, y_pred)
sns.set(font_scale=1.2)
plt.figure(figsize=(7,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão - Prognóstico de Falhas (RUL)')
plt.show()